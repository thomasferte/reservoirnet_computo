---
title: "Reservoir Computing in R: a Tutorial for Using reservoirnet to Predict Complex Time-Series"
# subtitle: "Example dedicated to `R` users"
author:
  - name: Thomas Ferté
    corresponding: false
    orcid: 0000-0001-8455-4665
    affiliations:
      - name: Inserm, Inria
        department: Inserm Bordeaux Population Health Research Center UMR 1219, Inria BSO, team SISTM, F-33000 Bordeaux, France
      - name: CHU de Bordeaux
        department: "Bordeaux Hospital University Center, Pôle de santé publique, Service d'information médicale, F-33000 Bordeaux, France"
  - name: Kalidou Ba
    corresponding: false
    orcid: 0000-0001-6552-265X
    affiliations:
      - name: Inserm, Inria
        department: Inserm Bordeaux Population Health Research Center UMR 1219, Inria BSO, team SISTM, F-33000 Bordeaux, France
  - name: Dan Dutartre
    corresponding: false
    orcid: 0000-0001-8210-461X
    affiliations:
      - name: Inria
        department: Inria BSO
  - name: Pierrick Legrand
    corresponding: false
    affiliations:
      - name: Inria
        department: Inria BSO, F-33000 Bordeaux, France
      - name: IMB
        department: IMB, Institut de Mathématiques de Bordeaux, UMR CNRS 5251
  - name: Vianney Jouhet
    corresponding: false
    orcid: 0000-0001-5272-2265
    affiliations:
      - name: Inserm
        department: Inserm Bordeaux Population Health Research Center UMR 1219, team AHeaD, F-33000 Bordeaux
      - name: CHU de Bordeaux
        department: "Bordeaux Hospital University Center, Pôle de santé publique, Service d'information médicale, F-33000 Bordeaux, France"
  - name: Rodolphe Thiébaut
    corresponding: false
    orcid: 0000-0002-5235-3962
    affiliations:
      - name: Inserm, Inria
        department: Inserm Bordeaux Population Health Research Center UMR 1219, Inria BSO, team SISTM, F-33000 Bordeaux, France
      - name: CHU de Bordeaux
        department: "Bordeaux Hospital University Center, Pôle de santé publique, Service d'information médicale, F-33000 Bordeaux, France"
  - name: Xavier Hinaut
    corresponding: false
    orcid: 0000-0002-1924-1184
    affiliations:
      - name: Inria
        department: Inria BSO, F-33000 Bordeaux, France
      - name: CNRS
        department: Univ. Bordeaux, CNRS, IMN, UMR 5293, Bordeaux, France
      - name: LaBRI
        department: LaBRI, Univ. Bordeaux, Bordeaux INP, CNRS UMR 5800.
  - name: Boris Hejblum
    email: boris.hejblum@u-bordeaux.fr
    corresponding: true
    orcid: 0000-0003-0646-452X
    affiliations:
      - name: Inserm, Inria
        department: Inserm Bordeaux Population Health Research Center UMR 1219, Inria BSO, team SISTM, F-33000 Bordeaux, France
date: last-modified
date-modified: last-modified
# description: |
#   This document provides a template based on the [`quarto`](https://quarto.org/) system for contributions to Computo, using the [`quarto journal extension`](https://github.com/computorg/computo-quarto-extension), the knitr kernel (R user) and [`renv`](https://rstudio.github.io/renv/articles/renv.html) to set-up the dependencies.
abstract: >+
  Reservoir Computing (RC) is a machine learning method based on neural networks that efficiently process information generated by dynamical systems. It has been successful in solving various tasks including time series forecasting, language processing or voice processing. RC is implemented in `Python` and `Julia` but not in `R`. This article introduces `reservoirnet`, an `R` package providing access to the `Python` API `ReservoirPy`, allowing `R` users to harness the power of reservoir computing. This article provides an introduction to the fundamentals of RC and showcases its real-world applicability through three distinct sections. First, we cover the foundational concepts of RC, setting the stage for understanding its capabilities. Next, we delve into the practical usage of `reservoirnet` through two illustrative examples. These examples demonstrate how it can be applied to real-world problems, specifically, regression of COVID-19 hospitalizations and classification of Japanese vowels. Finally, we present a comprehensive analysis of a real-world application of `reservoirnet`, where it was used to forecast COVID-19 hospitalizations at Bordeaux University Hospital using public data and electronic health records.
keywords: [Reservoir Computing, Covid-19, Electronic Health Records, Time series]
citation:
  type: article-journal
  container-title: "Computo"
  doi: "xxxx"
  url: https://computo.sfds.asso.fr/template-computo-quarto
  publisher: "Société Française de Statistique"
  issn: "2824-7795"
bibliography: references.bib
github-user: computorg
repo: "thomasferte/reservoirnet_computo"
draft: true # set to false once the build is running
published: false # will be set to true once accepted
format:
  computo-html: default
  computo-pdf: 
    echo: true
    tidy: styler
---

```{r, setup, include=FALSE}
options(prompt = 'R> ', continue = '+ ')
set.seed(1)
```

# Introduction

Reservoir Computing (RC) is a prominent machine learning method, proposed by @jaeger__2001, @maass_real-time_2002 and @lukosevicius_reservoir_2009
that has gained significant attention in recent years for its ability to efficiently process information generated by dynamical systems. This
innovative approach leverages the dynamics of a high-dimensional "reservoir" (we define it below) to perform complex computations and solve various tasks based on the response of this dynamical system to input signals. RC has demonstrated its efficacy in tackling various challenges, encompassing pattern classification and time series forecasting in applications ranging from electrocardiogram analysis to bird calls [@trouvain_canary_2021], language processing [@hinaut_real-time_2013], power plants, internet traffic, stock prices, and beyond [@lukosevicius_reservoir_2009; @tanaka_recent_2019].

Originally, the RC paradigm was implemented in artificial firing-rate neurons ("Echo State Networks", @jaeger__2001) and spiking neurons ("Liquid State Machine", @maass_real-time_2002) as a recurrent neural network (RNN) where the internal recurrent connections, denoted as the reservoir, are randomly generated and only the output layer (named "read-out") is trained. The reservoir projects temporal input signals onto a high-dimensional feature space, facilitating the learning of non-linear and temporal interactions. Thus, this recurrent layer contains high-dimensional non-linear recombination of the inputs and past states: it is a "reservoir of computations" from which useful information can be linearly extracted (or "read-out") to provide the desired outputs. This offers the advantage of decreasing the computing time compared to conventional RNNs while consistently maintaining performance [@vlachas_backpropagation_2020]. Besides, this RC paradigm fostered increasing interest thanks to its ability to be implemented on classical computers, as the hidden recurrent layer can be kept untrained. A wide range of physical media can be also used to replace it and @tanaka_recent_2019 recently reviewed this prolific field: from FPGA hardware [@penkovsky_efficient_2018], to spin waves using magnetic properties [@nakane_reservoir_2018], skrymions [@prychynenko_magnetic_2018] or optical implementations [@rafayelyan_large-scale_2020]. This provides interesting and potentially more efficient alternative to traditional machine learning computing.


RC leverages various hyperparameters to introduce prior knowledge about the relationship between input variables and output targets. But because the connections within the reservoir are randomly initialized, the same set of hyperparameters may exhibit diverse behaviors across different instances of the reservoir connections. This unpredictability makes it challenging to anticipate the performance of a particular hyperparameter setting, as identical settings may produce varying outcomes when applied to distinct instances of the reservoir. Moreover, selecting the most suitable hyperparameters often requires researchers to experiment with multiple combinations on a training dataset and evaluate their performance on a separate test set^[In this article, we employ the term "train set" to refer to the combined dataset consisting of both the training and validation sets, which are cycled through in a cross-validation manner.]. Although this approach can be resource-intensive and time-consuming, it is a compromise that is acceptable considering the rapid simulation capabilities offered by RC. Furthermore, there is a current absence of implementation in R, rendering the method challenging for users unfamiliar with Python [@trouvain_reservoirpy_2022] or Julia [@martinuzzi_reservoircomputingjl_2022].

Here, we offer comprehensive guidance to assist new users in maximizing the benefits of RC. Initially, a broad introduction to reservoir computing is presented in @sec-rcpresentation, followed in @sec-basicpackageuse by a tutorial on its application using `reservoirnet`, an R package built upon the `ReservoirPy` `Python` module [@trouvain_create_2022; @trouvain_reservoirpy_2022; @trouvain_reservoirpy_2020]. @sec-basicpackageuse then introduces the workflow usage on `reservoirnet` for RC with two basic use-cases, and finally, in @sec-studycase we investigate the various challenges associated with an advanced case-study leveraging RC for forecasting COVID-19 hospitalizations. This case-study exploration includes detailed guidance on the modeling strategy, the selection of hyperparameters, and the implementation process.

# RC presentation {#sec-rcpresentation}

RC is a machine learning paradigm which is most often implemented as Echo State Networks (ESNs), i.e. the firing-rate neuron version [@jaeger__2001]. An ESN is described by three matrices of connectivity: an input layer $W_{in}$, a recurrent layer $W$ and an output layer $W_{out}$. At each time step, the input vector $u_t$ is projected into the reservoir which is also combined with reservoir past state $x(t-1)$ through the recurrent connections. The output $y(t)$ is linearly read-out from the reservoir. Input $W_{in}$ and recurrent $W$ matrices are kept random; only the output matrix $W_{out}$ is trained in an offline or online method. Often a ridge regression (i.e. a regularized linear regression) is used to obtain the desired outputs $y(t)$ from the reservoir states $x(t)$. @fig-rcpresentation depicts the architecture. For simplicity, we will use the term "reservoir computing" for "Echo State Network" in the remainder of the paper.

```{r rcpresentation, echo=FALSE}
#| label: fig-rcpresentation
#| fig-cap: "Reservoir computing is composed of an input layer, a reservoir and an output layer. Connection between input layer and reservoir and inside reservoir are random. Only the output layer is optimized based on a ridge regression. Adapted from @trouvain_reservoirpy_2020"
#| out.width: "100%"
knitr::include_graphics("images/image1.png")
```


The input layer $u(t)$ is an $M$-dimension vector, where $M$ is the number of input time series, which corresponds to the values of the input time series at time $t$ where $t = 1, \dots, T$. The reservoir layer $x(t)$ is an $N_{res}$-dimensional vector where $N_{res}$ is the number of nodes in the reservoir. The value $x(t)$ is defined as follow:
\begin{equation}
x( t+1 ) = ( 1 - \alpha )  x ( t) + \alpha \: tanh\left( W x(t) + W_{in} u(t+1)\right).
\end{equation}

The leaking rate $\alpha \in [0, 1]$ defines the update rate of the nodes. The closer $\alpha$ is to $1$, the more the reservoir is sensitive to new inputs $u(t)$. Therefore, the reservoir state at time $t+1$ denoted $x(t+1)$ depends on the reservoir state at the previous time $x(t)$ and the new inputs $u(t+1)$. The function $tanh()$ represents the activation function, applied element-wise to each component of the vector, ensuring that each node’s activation is scaled between $-1$ and $1$. Both $W_{in}$ and $W$ are random matrices of size $N_{res} \times M$ and $N_{res} \times N_{res}$ respectively.

$W_{in}$ is a matrix (usually sparse) generated using a Bernoulli (bimodal) distribution where each value can be either $-I_{scale}(m)$ or $I_{scale}(m)$ with an equal probability where $m = 1, \dots, M$ corresponds to a given feature in the input layer. The input scaling, denoted $I_{scale}$, is a hyperparameter coefficient common to all features from the input layer or specific to each feature $m$. In that case, the more important the feature is, the greater should be its input scaling. $W$ is a matrix (usually sparse) where values are generated from a Gaussian distribution $\mathcal{N}(0,1)$. Then, the $W$ matrix is scaled according to the defined spectral radius, a hyperparameter defining the highest eigen value of $W$.

The final layer is a linear regression with ridge penalization where the
explanatory features are the reservoir state and the variable to be
explained is the outcome to predict such that:
$$W_{out} = YX^T ( XX^T + \lambda  I)^{ -1 }.$$
Where x(t) and y(t) are accumulated in X and Y respectively such that:
$$
X = \begin{bmatrix} x(1) \\ x(2) \\ ... \\ x(T) \end{bmatrix}
\text{ and } Y = \begin{bmatrix} y(1) \\ y(2) \\ ... \\ y(T) \end{bmatrix}.
$$
The parameter $\lambda$ is the ridge penalization which aims to prevent overfitting. Additionally, one can also connect the input layer to the output layer to the reservoir nodes. In that case, $X$ is the accumulation of both such that :
$$X = \begin{bmatrix} x(1), u(1) \\ x(2), u(2) \\ ... \\ x(T), u(T) \end{bmatrix}
\text{ and } Y = \begin{bmatrix} y(1) \\ y(2) \\ ... \\ y(T) \end{bmatrix}.$$

Overall, there are four main hyperparameters to be chosen by the user: i) the leaking rate which defines the memory of the RC, ii) the input scaling which defines the relative importance of the features, iii) the spectral radius which defines the connections of the neurons inside the reservoir which in turn defines the degree of non-linear combination of features, and iv) the ridge penalization which controls the degree of overfitting. The choice of hyperparameters often requires the user to evaluate the performance of different combinations of hyperparameters on a validation set before selecting the optimal combination to forecast on the test set.


# Usage workflow {#sec-basicpackageuse}

In this section, we will cover the basics of `reservoirnet` use including
installation, classification and regression. A more in depth description is provided in
 @sec-studycase with the covid-19 forecast use case.


## Installation

`reservoirnet` is an `R` package making the `Python` module  `ReservoirPy`
easily callable from `R` using `reticulate` R package @reticulate_2024. It is available on CRAN (see
[https://cran.r-project.org/package=reservoirnet](https://cran.r-project.org/package=reservoirnet)) and can be installed using:

```{r eval=FALSE}
# Install reservoirnet package from CRAN
install.packages("reservoirnet")
```

Alternatively, it can also be installed from GitHub:

```{r eval=FALSE}
# Install reservoirnet package from GitHub
devtools::install_github(repo = "reservoirpy/reservoirR")
```

For `reservoirnet` to work, it will require `Python` version 3.8 or higher, along with the `reservoirpy` module which can be installed with the `install_reservoirpy()` function:

```{r eval=FALSE}
reservoirnet::install_reservoirpy()
```

Reservoir Computing (RC) is well suited to both regression and
classification tasks. We will introduce a simple example for both task.

## Package workflow overview

```{r schemaworkflow, echo=FALSE}
#| label: fig-schemaworkflow
#| fig-cap: "Worflow of `reservoirnet`."
#| out.width: "75%"
knitr::include_graphics("images/schema_workflow.png")
```

The workflow of `reservoirnet` is described in @fig-schemaworkflow. A reservoir model is created by the association of an input layer (a matrix), a reservoir, and an output layer. Both the reservoir and the output layer are created using the function `reservoirnet::createNode()` by specifying the node type (i.e., either `Reservoir` or `Ridge`).

This function accepts several arguments to specify the hyperparameters of the reservoir and will be detailed in future sections. After the reservoir and output layer are created, they can be connected using the `%>>%` operator, a specific pipe operator dedicated to `reservoirnet`. The model can then be fitted using `reservoirR_fit()` and used to make predictions on a new dataset using `predict_seq()`.

## Basic regression use-case {#sec-basicregression}

### Covid-19 data

In this first use-case, we will introduce the fundamental usage of the `reservoirnet` package. This demonstration will be conducted using the COVID-19 dataset that is included within the package. These data encompass hospitalization, positive RT-PCR (Reverse Transcription Polymerase Chain Reaction) results, and overall RT-PCR data sourced from Santé Publique France, which are publicly available on data.gouv.fr (for further details, refer to `help(dfCovid)`). Our primary objective is to predict the number of hospitalized patients 14 days into the future. To accomplish this, we will initially train our model on data preceding the date of January 1, 2022, and then apply it to forecast values using the following dataset.

We can proceed by loading useful packages - namely `ggplot2` @wickham_ggplot2_2016 and `dplyr` @wickham_dplyr_2023, data and define the task:

```{r message=FALSE, warning=FALSE}
# Load usefull packages
library(dplyr)
library(ggplot2)
library(reservoirnet)
# load dfCovid data from the reservoirnet package which contains Covid data
data("dfCovid")
# Set the forecast horizon to 14 days
dist_forecast = 14
# Set the train-test split to 2022-01-01
traintest_date = as.Date("2022-01-01")
```

Due to the substantial fluctuations observed in both RT-PCR metrics, our initial step involves applying a moving average computation over the most recent 7-day periods for these features. Additionally, we augment the dataset by introducing an `outcome` column and an `outcomeDate` column, which will serve as valuable inputs for model training. Moreover, we calculate the `outcome_deriv` as the difference between the outcome and the number of hospitalized patients (`hosp`), representing the variation in hospitalization in relation to the current count of hospitalized individuals. The resulting smoothed data is visualized in @fig-covidintro.

```{r}
dfOutcome <- dfCovid %>%
  # outcome at 14 days
  mutate(outcome = lead(x = hosp, n = dist_forecast),
         # Create a new column 'outcome' which contains the number of
         # hospitalizations ('hosp') shifted forward by 'dist_forecast' days
         # (14 days). This represents the outcome we want to predict.

         outcomeDate = date + dist_forecast,
         # Create a new column 'outcomeDate' which is the current date plus the
         # forecast period (14 days).
         
         outcome_deriv = outcome - hosp) %>%
         # Create a new column 'outcome_deriv' which is the difference between
         # the predicted outcome and current hospitalizations.
         # This represents the change in hospitalizations over the forecast
         # period.

  # rolling average for tested and positive_pcr
  mutate_at(.vars = c("Positive", "Tested"),
            .funs = function(x) slider::slide_dbl(.x = x,
                                                  .before = 6,
                                                  .f = mean))
            # Apply a rolling mean (7-day average) to the 'Positive' and
            # 'Tested' columns.
            # The 'slider::slide_dbl' function is used to calculate the mean
            # over a window of 7 days (current day + 6 days before). This
            # smooths out daily fluctuations and provides a better trend
            # indicator.

```

```{r covidintro, echo = FALSE}
#| label: fig-covidintro
#| fig-cap: "Hospitalizations, number of positive RT-PCR and number of RT-PCR of Bordeaux University Hospital."
# Create a figure with hospitalizations, positive and tested RT-PCR from covid data
dfOutcome %>%
  tidyr::pivot_longer(cols = c("hosp", "Positive", "Tested")) %>%
  ggplot2::ggplot(mapping = aes(x = date, y = value)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  theme_minimal() +
  labs(color = "") +
  theme(legend.position = "bottom")
```

### First reservoir

```{r schemaregression, echo=FALSE}
#| label: fig-schemaregression
#| fig-cap: "Regression use case: Forecasting the number of hospitalized patients 14 days ahead."
#| out.width: "75%"
knitr::include_graphics("images/regression_usecase.PNG")
```

The objective of this task is to train a RC model using the input features to forecast the number of hospitalized patients 14 days ahead, as illustrated in Figure @fig-schemaregression.

Setting a reservoir is done with the `createNode()` function. The important hyperparameters are the following :

-   Number of nodes (`units`) : it corresponds to the number of nodes inside the reservoir. Usually, the more the better, but more nodes increases the computation time.
-   Leaking rate (`lr`) : the leaking rate corresponds to the balance between the new inputs and the previous state. A leaking rate of 1 only consider information from new inputs.
-   Spectral radius (`sr`): the spectral radius is the largest eigenvalue in modulus of the reservoir connectivity matrix. A small spectral radius induces stable dynamics inside the reservoir, a high spectral radius induces a chaotic regime inside the reservoir.
-   Input scaling (`input_scaling`): the input scaling is a gain applied to the input features of the reservoir.
-   Warmup (`warmup`) : it corresponds to the number of time step during which the data are propagating into the reservoir but not used to fit the output layer. This hyperparameter is set in the `reservoirR_fit()` function.

In addition, we can set the seed (`seed`). Because the reservoir connections are set at random, setting the seed is a good approach to ensure reproducibility.

For this part of the tutorial, we will set the hyperparameter at a given value. Hyperparameter optimization will be detailed at @sec-studycase.

```{r}
# Create a reservoir computing node using the 'createNode' function from the
# reservoirnet package.
# Arguments:
# - nodeType = "Reservoir": Specify the type of node to be a reservoir.
# - seed = 1: Set the seed for reproducibility, ensuring consistent results
#             when the model is run multiple times.
# - units = 500: Set the number of reservoir units (neurons) to 500.
# - lr = 0.7: Set the leakage rate (lr) of the reservoir, which controls how
#             quickly the reservoir state decays over time.
# - sr = 1: Set the spectral radius (sr) of the reservoir, which influences the
#           stability and memory capacity of the reservoir.
# - input_scaling = 1: Set the input scaling factor, which scales the input
#                       signal before it is fed into the reservoir.

reservoir <- reservoirnet::createNode(nodeType = "Reservoir",
                                      seed = 1,
                                      units = 500,
                                      lr = 0.7,
                                      sr = 1,
                                      input_scaling = 1)
```

Then we can feed the data to the reservoir and see the activation state of the reservoir $x(t)$. To do so, we first prepare the data and transform it to a matrix.

```{r}
## select explanatory features of the train set and transform it to an array
X <- dfOutcome %>%
  filter(outcomeDate < traintest_date) %>%
  select(hosp, Positive, Tested) %>%
  as.matrix()
```

Then we run the `predict_seq()` function. It takes as input a node (i.e a reservoir or a reservoir associated with an output layer) and the feature matrix.

```{r}
# Generate the state of the reservoir using the 'predict_seq' function from the
# reservoirnet package.
# Arguments:
# - node = reservoir: The reservoir computing node created earlier.
# - X = X: The input data matrix containing the features 'hosp', 'Positive',
#           and 'Tested'.
# The function computes the state of the reservoir for each time step in the
# input sequence, effectively transforming the input data into the reservoir's
# high-dimensional state space.

reservoir_state <- predict_seq(node = reservoir, X = X)
```

Now we can visualize node activation using the `plot()` function presented at @fig-nodeactivationbad .

```{r nodeactivationbad}
#| label: fig-nodeactivationbad
#| fig-cap: "20 random nodes activation over time."
# Plot the reservoir state activation over time
plot(reservoir_state)
```

Numerous nodes within the system exhibit a consistent equilibrium state. The challenge arises when the output layer attempts to extract knowledge from these nodes, as they do not convey meaningful information. This issue can be attributed to the disparate scales of the features. To address this concern, a practical approach involves normalizing the features by dividing each of them by their respective maximum values, thereby scaling them within the range of $-1$ to $1$ by dividing by the maximum of the absolute value. Of note, here the features will be scaled between $0$ and $1$ because all features are positive.

```{r}
# Standardise features by dividing by the maximum value can improve performance
# After standardisation, all features are on a similar scale which helps RC
stand_max <- function(x) return(x/max(abs(x)))
# scaled features
Xstand <- dfOutcome %>%
  filter(date < traintest_date) %>%
  select(hosp, Positive, Tested) %>%
  mutate_all(.funs = stand_max) %>%
  as.matrix() %>%
  as.array()
```

We then feed them to the reservoir and plot the node activation again. Compared to @fig-nodeactivationbad, the obtained node activation at @fig-nodeactivationgood shows interesting trend outputs as no node seems saturated.

```{r nodeactivationgood}
#| label: fig-nodeactivationgood
#| fig-cap: "20 random node activation over time. Scaled features."
# feed the scaled features to the reservoir
reservoir_state_stand <- predict_seq(node = reservoir,
                                     X = Xstand,
                                     reset = TRUE)
# plot the output
plot(reservoir_state_stand)
```

### Forecast

In order to train the reservoir, we should train the last layer which
linearly combines the neuron's output.

#### Set the ESN

Initially, we establish the output layer with the `createNode()` function, incorporating a ridge penalty set at `1e3`. It's important to note that this hyperparameter can be subject to optimization, a topic that will be explored in @sec-studycase. This parameter plays a pivotal role in fine-tuning the model's conformity to the data. When set excessively high, the risk of underfitting arises, whereas setting it too low can lead to overfitting. We connect the output layer to the reservoir, with the `%>>%` operator, making the model ready to be trained.

```{r}
readout <- reservoirnet::createNode(nodeType = "Ridge",
                                    ridge = 1e3)
# Create a readout node using ridge regression with the 'createNode' function
# from the reservoirnet package.
# Arguments:
# - nodeType = "Ridge": Specify the type of node to be a ridge regression
#                       readout.
# - ridge = 1e3: Set the regularization parameter (ridge) for the ridge
#                 regression to 1000.
# Ridge regression is used to prevent overfitting by adding a penalty on the
# size of the coefficients.

model <- reservoir %>>% readout
# Link the reservoir and readout nodes to form a complete reservoir computing
# model. The '%>>%' operator connects the high-dimensional state generated by
# the reservoir to the readout layer, allowing the model to learn the mapping
# from the reservoir states to the target outputs.
```

#### Set the data

First we separate the train set on which we will learn the ridge coefficients and the test set on which we will make the forecast. We define the train set to be all the data before 2022-01-01 and the test data to be all the data to have forecast both on train and test sets.

```{r}
# Perform some data management to isolate train and test sets
# train set
dftrain <- dfOutcome %>% filter(outcomeDate <= traintest_date)
yTrain <- dftrain %>% select(outcome)
yTrain_variation <- dftrain %>% select(outcome_deriv)
xTrain <- dftrain %>% select(hosp, Positive, Tested)
# test set
xTest <- dfOutcome %>% select(hosp, Positive, Tested)
```

We standardize with the same formula as seen before. We learn the standardization on the training set and apply it on the test set. Then we convert the dataframe to matrix.

```{r results=FALSE}
# copy train and test sets
xTrainstand <- xTrain
xTeststand <- xTest
# standardise based on training set values
ls_fct_stand <- apply(xTrain,
                      MARGIN = 2,
                      FUN = function(x) function(feature) feature/(max(x)))
lapply(X = names(ls_fct_stand),
       FUN = function(x){
         xTrainstand[,x] <<- ls_fct_stand[[x]](feature = xTrain[,x])
         xTeststand[,x] <<- ls_fct_stand[[x]](feature = xTest[,x])
         return()
       })
# convert to array
lsdf <- lapply(list(yTrain = yTrain,
                    yTrain_variation = yTrain_variation,
                    xTrain = xTrainstand,
                    xTest = xTeststand),
               function(x) as.matrix(x))
```

#### Train the model and predict

We then feed the reservoir with the train set using the `reservoirR_fit()` function. To do so, we set a `warmup` of `30` days during which the data are propagating into the reservoir but not used to fit the output layer.

```{r results='hide'}
### train the reservoir ridge output
fit <- reservoirnet::reservoirR_fit(node = model,
                                    X = lsdf$xTrain,
                                    Y = lsdf$yTrain,
                                    warmup = 30,
                                    reset = TRUE)
```

Now that the ridge layer is trained, we can forecast using the `predict_seq()` function. We set the parameter `reset` to `TRUE` in order to clean the reservoir from the data used by the training set.

```{r}
# Forecast with the trained reservoir on the test data
vec_pred <- reservoirnet::predict_seq(node = fit$fit,
                                      X = lsdf$xTest,
                                      reset = TRUE)
```

```{r}
#| label: fig-forecast
#| fig-cap: "Forecast"
# Make figure to represent forecast on the train and test sets.

dfOutcome %>%
  mutate(pred = vec_pred) %>%
  na.omit() %>%
  ggplot(mapping = aes(x = outcomeDate)) +
  geom_line(mapping = aes(y = outcome,
                          color = "observed")) +
  geom_line(mapping = aes(y = pred,
                          color = "forecast")) +
  annotate("rect",
           xmin = traintest_date,
           xmax = max(dfOutcome$outcomeDate, na.rm = T),
           ymin = 0,
           ymax = max(dfOutcome$outcome, na.rm = T)*1.1, 
           alpha = .2) +
  annotate("text", label = "Test set",
           x = as.Date("2022-08-01"), y = 2200, size = 7) +
  annotate("text", label = "Train set",
           x = as.Date("2021-03-01"), y = 2200, size = 7) +
  scale_color_manual(values = c("#3772ff", "#080708")) +
  theme_minimal() +
  labs(color = "", x = "Date", y = "Hospitalizations")
```

We observe that the model forecast at @fig-forecast is not fully accurate, both on the test set and the train set. In that case, one option could be to reduce ridge penalization to fit more closely the data, the optimization of ridge hyperparameter will be discussed at  @sec-studycase. Another possibility is to ease the learning of the algorithm by forecasting the variation of the hospitalization instead of the number of hospitalized patients. For that step, we will learn on the `outcome_deriv` contained in `yTrain_variation` data which is defined outcome as `outcome_deriv = outcome - hosp`. As depicted at @fig-figForecastDerivvsRaw, this strategy improved the model forecast.

```{r results="hide"}
## Fit reservoir on outcome variation instead of raw outcome
fit2 <- reservoirnet::reservoirR_fit(node = model,
                                     X = lsdf$xTrain,
                                     Y = lsdf$yTrain_variation,
                                     warmup = 30,
                                     reset = TRUE)
## Get the forecast on the test set
vec_pred2_variation <- reservoirnet::predict_seq(node = fit2$fit,
                                                 X = lsdf$xTest,
                                                 reset = TRUE)
## Transform the outcome variation forecast into hospitalization forecast
vec_pred2 <- vec_pred2_variation + xTest$hosp
```


```{r figForecastDerivvsRaw}
#| label: fig-figForecastDerivvsRaw
#| fig-cap: "Covid-19 hospitalizations forecast. The model is either trained to forecast the number of hospitalizations (denoted Raw) or the variation of the hospitalizations compared to current level of hospitalisation (denoted Variation)"
## Plot the results
dfOutcome %>%
  mutate(Raw = vec_pred,
         Variation = vec_pred2) %>%
  tidyr::pivot_longer(cols = c(Raw, Variation),
                      names_to = "Outcome_type",
                      values_to = "Forecast") %>%
  na.omit() %>%
  ggplot(mapping = aes(x = outcomeDate)) +
  geom_line(mapping = aes(y = outcome,
                          color = "observed")) +
  geom_line(mapping = aes(y = Forecast,
                          color = "Forecast")) +
  annotate("rect",
           xmin = traintest_date,
           xmax = max(dfOutcome$outcomeDate, na.rm = T),
           ymin = 0,
           ymax = max(dfOutcome$outcome, na.rm = T)*1.1, 
           alpha = .2) +
  annotate("text", label = "Test set",
           x = as.Date("2022-08-01"), y = 2200, size = 5) +
  annotate("text", label = "Train set",
           x = as.Date("2021-03-01"), y = 2200, size = 5) +
  facet_wrap(Outcome_type ~ .,
             labeller = label_bquote(cols = "Outcome" : .(Outcome_type))) +
  scale_color_manual(values = c("#3772ff", "#080708")) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(color = "", x = "Date", y = "Hospitalizations")
```

## Classification

### The Japanese vowel dataset

This example is largely inspired from the [classification tutorial of reservoirpy](https://github.com/reservoirpy/reservoirpy/blob/master/tutorials/5-Classification-with-RC.ipynb). To illustrate the classification task, we will use the Japanese vowel dataset (@kudo_multidimensional_1999). The data can be loaded from `reservoirnet` as follow :

```{r}
# Get the Japanese vowels dataset using the 'generate_data' function from the
# reservoirnet package.
# The dataset contains preprocessed features and labels for classification.
# Then we isolate train and test sets
japanese_vowels <- reservoirnet::generate_data(dataset = "japanese_vowels")[[1]]
X_train <- japanese_vowels$X_train
Y_train <- japanese_vowels$Y_train
X_test <- japanese_vowels$X_test
Y_test <- japanese_vowels$Y_test
```

The dataset comprises 640 vocalizations of the Japanese vowel \ae, contributed by nine distinct speakers. Each vocalization represents a time series spanning between 7 and 29 time steps, encoded as a 12-dimensional vector denoting the Linear Prediction Coefficients (LPC). A visual representation of six distinct utterances from the test set, originating from three different speakers, is depicted in @fig-vowelpresentation.

```{r vowelpresentation, echo = FALSE}
#| label: fig-vowelpresentation
#| fig-cap: "Vowel dataset, sample with 3 speakers and 2 utterance each."
# Make a figure of the Vowel dataset of selected participants.
vec_sample <- c(1, 2, 41, 42, 71, 72)
dfplot_vowel <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]] == 1)
                   X_test[[i]] %>%
                     as.data.frame() %>%
                     tibble::rowid_to_column(var = "Time") %>%
                     tidyr::pivot_longer(cols = -Time,
                                         names_to = "component",
                                         values_to = "LPC") %>%
                     mutate(speaker = speaker, .before = 1,
                            uterrance = i) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplot_vowel, mapping = aes(x = Time, y = LPC, color = component)) +
  geom_line() +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  theme_minimal() +
  theme(legend.position = "none")

```

```{r schemaclassif, echo=FALSE}
#| label: fig-schemaclassif
#| fig-cap: "Classification use-case, identifying the speaker from an utterance."
#| out.width: "75%"
knitr::include_graphics("images/classif_usecase.PNG")
```

The primary objective involves the attribution of each utterance to its respective speaker, this is denoted as classification or sequence-to-vector encoding. The secondary objective involves the attribution of each time step of each utterance to its speaker, this is denoted as transduction or sequence-to-sequence encoding. While this second approach may seem somewhat superfluous in this context, it could be useful, for example, in cases where multiple speakers take turns speaking, allowing us to identify which sequence belongs to each individual speaker. Figure @fig-schemaregression illustrates this task.

### Classification (sequence-to-vector model)

The first approach is the sequence-to-vector encoding. For this task we aim to predict the speaker of the whole utterance (i.e the label is assigned to the whole sequence). We first start by creating the reservoir and the output layer using `createNode()` function.

```{r}
reservoir <- reservoirnet::createNode("Reservoir", units = 500,
                                      lr=0.1, sr=0.9,
                                      seed = 1)
# Create a reservoir computing node with 500 units using the 'createNode'
# function from the reservoirnet package.
# Arguments:
# - units = 500: Set the number of reservoir units (neurons) to 500.
# - lr = 0.1: Set the leakage rate (lr) of the reservoir to 0.1, controlling
#             how quickly the reservoir state decays over time.
# - sr = 0.9: Set the spectral radius (sr) of the reservoir to 0.9, influencing
#             the stability and memory capacity of the reservoir.
# - seed = 1: Set the seed for reproducibility, ensuring consistent results
#             when the model is run multiple times.
readout <- reservoirnet::createNode("Ridge",ridge=1e-6)
# Create a readout node using ridge regression with the 'createNode' function
# from the reservoirnet package.
# Arguments:
# - ridge = 1e-6: Set the regularization parameter (ridge) for the ridge
#                 regression to 1e-6.
# Ridge regression is used to prevent overfitting by adding a penalty on the
# size of the coefficients.
```

To perform this task, we need to modify the training and testing processes. Leveraging the inherent inertia of the reservoir, information from preceding time steps is preserved, effectively endowing the RC with a form of memory. Consequently, the final state vector encapsulates insights gathered from all antecedent states. In the context of the sequence-to-vector encoding task, only the final state is used. To simplify this process, we introduce the `last_reservoir_state()` function, which extracts the final reservoir state. This process is executed as follows:

```{r}
states_train <- reservoirnet::last_reservoir_state(node = reservoir, X = X_train)
```

Then, we use only the final state for prediction. We first extract the final state using the `last_reservoir_state()` function and then use the trained readout to predict the vowel using the `predict_seq()` function with the `seq_to_vec` parameter set to `TRUE`:

```{r results='hide'}
# Fit the reservoir using the last state vector (each observation is the whole
# vowel sequence)
res <- reservoirnet::reservoirR_fit(node = readout, X = states_train, Y = Y_train)
```

Then we can perform the prediction using only the final state. We first get the final state using the `last_reservoir_state()` function and use the trained readout to predict the vowel using the `predict_seq()` function with the `seq_to_vec` parameter set to `TRUE`.

```{r}
# The operation is repeated for the test set :
states_test <- reservoirnet::last_reservoir_state(node = reservoir, X = X_test)
Y_pred <- reservoirnet::predict_seq(node = readout, X = states_test, seq_to_vec = TRUE)

```

@fig-seqtovec shows the prediction for the 6 utterances depicted at @fig-vowelpresentation where the model correctly identifies the speaker.

```{r seqtovec}
#| label: fig-seqtovec
#| fig-cap: "Prediction in a sequence-to-sequence approach 6 samples with 3 speakers and 2 utterance each. The speaker to predict is depicted in blue. For each of the 6 utterance, the model correctly identifies the speaker."
# A figure represents the performance on the test set
dfplotseqtovec <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]][1,] == 1)
                   Y_pred[[i]] %>%
                     as.data.frame() %>%
                     tidyr::pivot_longer(cols = everything(),
                                         names_to = "pred_speaker",
                                         values_to = "prediction") %>%
                     mutate(pred_speaker = gsub(x = pred_speaker,
                                                pattern = "V", "")) %>%
                     mutate(speaker = speaker, .before = 1,
                            uterrance = i,
                            target = speaker == pred_speaker) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplotseqtovec,
       mapping = aes(x = pred_speaker,
                     y = prediction,
                     fill = target)) +
  geom_bar(stat = "identity") +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  scale_fill_manual(values = c("#BDBDBD", "#A3CEF1")) +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(y = 'Score',
       x = "Speaker")
```

Then, we can also compute the overall accuracy :

```{r}
# The overall accuracy is evaluated
accuracy <- function(pred, truth) mean(pred == truth)

Y_pred_class <- sapply(Y_pred,
                       FUN = function(x) apply(as.matrix(x),1,which.max))
Y_test_class <- sapply(Y_test,
                       FUN = function(x) apply(as.matrix(x),1,which.max))

score <- accuracy(pred = Y_test_class, truth = Y_pred_class)

print(paste0("Accuracy: ", round(score * 100,3) ,"%"))
```

### Transduction (sequence-to-sequence model)

For this task, the goal is to predict the speaker for each time step of each utterance. The first step is to get the data where the label is repeated for each time step. This is easily done with the `repeat_targets` argument as follow :

```{r}
# For this new task where we want to forecast for each time step (instead of each utterance)
# we start by getting the data in the appropriate format
# Then we split the train and test data
japanese_vowels <- reservoirnet::generate_data(
    dataset = "japanese_vowels",
    repeat_targets=TRUE)$japanese_vowels
X_train <- japanese_vowels$X_train
Y_train <- japanese_vowels$Y_train
X_test <- japanese_vowels$X_test
Y_test <- japanese_vowels$Y_test
```

Then we can train a simple Echo State Network to solve this task. For this example, we will connect both the input layer and the reservoir layer to the readout layer, which is performed by the `%>>%` operator. This direct connection between the input layer and the output layer can be particularly useful when the relationship between the input sequences and the output is mostly linear, potentially improving performance, especially in tasks where linear dependencies play a significant role. Section @sec-studycase will explore this aspect in more detail through the SARS-CoV-2 prediction task.

```{r}
# Create an input, a reservoir and an output layers
source <- createNode("Input")
readout <- createNode("Ridge",ridge=1e-6)
reservoir <- createNode("Reservoir",units = 500,lr=0.1, sr=0.9, seed = 1)
# Connect the input layer to the reservoir and connect both the input layer and
# the reservoir to the output layer
model <- list(source %>>% reservoir, source) %>>% readout
```

We can then fit the model and predict the labels for the test data. The `reset` parameter is set to `TRUE` to remove information from the reservoir from the training process.

```{r results='hide'}
# Fit the RC model
model_fit <- reservoirnet::reservoirR_fit(node = model,
                                          X = X_train,
                                          Y = Y_train,
                                          warmup = 2)
# Predict with the fitted model
Y_pred <- reservoirnet::predict_seq(node = model_fit$fit,
                                    X = X_test,
                                    reset = TRUE)
```

From the `Y_pred` and `Y_test` we represent at @fig-figseqtoseq the predictions for the same patients as in @fig-vowelpresentation.

```{r figseqtoseq}
#| label: fig-figseqtoseq
#| fig-cap: "Prediction in a sequence-to-sequence approach 6 samples with 3 speakers and 2 utterance each. The higher the score of the speaker, the lighter the color."
#| fig-height: 8

# Make a graph with a label for each time of each utterance
dfplotseqtoseq <- lapply(vec_sample,
                 FUN = function(i){
                   speaker <- which(Y_test[[i]][1,] == 1)
                   Y_pred[[i]] %>%
                     as.data.frame() %>%
                     tibble::rowid_to_column(var = "Time") %>%
                     tidyr::pivot_longer(cols = -Time,
                                         names_to = "pred_speaker",
                                         values_to = "prediction") %>%
                     mutate(pred_speaker = gsub(x = pred_speaker,
                                                pattern = "V", ""),
                            speaker = speaker,
                            uterrance = i,
                            .before = 1) %>%
                     return()
                 }) %>%
  bind_rows()

ggplot(dfplotseqtoseq, mapping = aes(x = Time,
                                     y = pred_speaker,
                                     fill = prediction)) +
  geom_tile() +
  facet_wrap(uterrance ~ speaker,
             labeller = label_bquote(cols = "speaker" : .(speaker)),
             ncol = 2) +
  scale_fill_gradient2(low = "#8ECAE6", high = "#FB8500", mid = "#023047",
                       midpoint = 0) +
  theme_minimal() +
  labs(y = 'Predicted speaker',
       fill = "Prediction score")
```

For those 6 utterances, the model correctly identify the speaker for most of the time steps. We can then evaluate the overall accuracy of the model :

```{r}
# Compute the accuracy
Y_pred_class <- sapply(Y_pred, FUN = function(x) apply(as.matrix(x),
                                                       1,
                                                       which.max))
Y_test_class <- sapply(Y_test, FUN = function(x) apply(as.matrix(x),
                                                       1,
                                                       which.max))
score <- accuracy(array(unlist(Y_pred_class)), array(unlist(Y_test_class)))

print(paste0("Accuracy: ", round(score * 100,3) ,"%"))
```

# Avanced case-study: Covid-19 hospitalizations forecast {#sec-studycase}

## Introduction

Since late 2020, millions of cases of SARS-CoV-2 infection have been documented across the globe [@world_health_organisation_who_2020; @noauthor_estimating_2022; @carrat_evidence_2021]. This ongoing pandemic has exerted significant strain on healthcare systems, resulting in a surge in hospitalizations. This surge, in turn, necessitated modifications to the healthcare infrastructure and gave rise to population-wide lockdown measures aimed at preventing the saturation of healthcare facilities [@simoes_organisation_2021; @hubner_surgery_2020; @kim_health_2020]. The capacity to predict the trajectory of the epidemic on a regional scale is of paramount importance for effective healthcare system management.

Numerous COVID-19 forecasting algorithms have been proposed using different methods (e.g ensemble, deep learning, mechanistic), yet none has proven entirely satisfactory [@cramer_evaluation_2022-1; @rahimi_review_2021]. In France, short-term forecasts with different methods have been evaluated with similar results [@paireau_ensemble_2022; @carvalho_analysis_2021; @mohimont_convolutional_2021; @pottier_forecast_2021]. In this context a machine learning algorithm based on linear regression with elastic-net penalization, leveraging both Electronic Health Records (EHRs) and public data, was implemented at Bordeaux University Hospital [@ferte_benefit_2022]. This model, which aimed at forecasting the number of hospitalized patients at 14 days, showed good performance but struggled to accurately anticipate dynamic shifts of the epidemic.

RC has been used in the context of covid-19 epidemic forecast [@kmet_bezier_2019; @liu_nanophotonic_2023; @ray_optimized_2021; @zhang_sentiment_2023; @ghosh_reservoir_2021]. Among them, @ghosh_reservoir_2021, @liu_nanophotonic_2023 and @ray_optimized_2021 used it to forecast epidemic, @zhang_sentiment_2023 performed sentiment analysis and @kmet_bezier_2019 used it to solve optimal control related to vaccine. The evaluation of RC for epidemic forecast showed promising results in all approaches, being competitive with Long-Short Term Memory (LSTM) and Feed-Forward Neural Network (FFNN) in @ray_optimized_2021. However, the test period was short for @ghosh_reservoir_2021} (21 and 14 days) and @ray_optimized_2021 (86 days) making it difficult to evaluate the behavior of the methods during epidemic dynamic shift. This was not the case for @liu_nanophotonic_2023 (6 months) but they implemented daily ahead forecast which would be difficult to use to manage a hospital. Finally, all three implementations used only one time series as input whereas it has been shown that using different data sources could improve forecast @ferte_benefit_2022. Therefore, it is still difficult to assess the usefulness of RC over a large period and using many time series as inputs.

RC can be viewed as an extension of penalized linear regression, where inputs undergo processing by a reservoir, introducing the capacity for memory and non-linear combinations. Given the effectiveness of penalized linear regression in COVID-19 forecasting, as highlighted in @ferte_benefit_2022, and the promising results exhibited by RC in epidemic forecasting, as demonstrated in studies such as @ghosh_reservoir_2021, @liu_nanophotonic_2023, and @ray_optimized_2021, we have opted to employ RC for the prediction of hospitalizations at 14 days at the University Hospital of Bordeaux.

The aim of this study is to showcase the use of `reservoirnet` for an advanced use case in forecasting the SARS-CoV-2 pandemic. Several architectural choices will be evaluated, such as the connection between the input layer and the output layer, and the use of either individual input scaling per feature or a common input scaling. The performance of Reservoir Computing (RC) will be compared with elastic-net penalized regression (identified as the optimal model in @ferte_benefit_2022), while a more in-depth comparison with other methods can be found in @ferte_reservoir_2024.

## Methods

### Data

The study utilized aggregated data spanning from May 16, 2020, to January 17, 2022, regarding the COVID-19 epidemic in France, drawing from various sources to enhance forecasting accuracy. These sources encompassed epidemiological statistics from Santé Publique France, weather data from the National Oceanic and Atmospheric Administration (NOAA), both providing department-level data [@smith_integrated_2011; @etalab_les_2020] and Electronic Health Record (EHR) data from the Bordeaux Hospital providing hospital-level data. All data were daily updated. Santé Publique France data included information on hospitalizations, RT-PCR tests, positive RT-PCR results, variant prevalence, and vaccination data, categorized by age groups. NOAA data contributed temperature, wind speed, humidity, and dew point data, allowing for the computation of the COVID-19 Climate Transmissibility Predict Index [@roumagnac_etude_2021]. EHRs data included hospitalizations, ICU admissions, ambulance service records, and emergency unit notes, with relevant COVID-19-related concepts extracted from the notes. Data are discussed more in depth in @ferte_benefit_2022.

First derivative over the last $7$ days were computed to enrich model information. To take into account measurement error and daily noise variation, data were smoothed using a local polynomial regression with a span of 21 days. As previously described, input features were scaled between -1 and 1 by dividing the observed value by the maximum of the absolute value of the given input feature.

All data are publicly available. Weather data can be obtained from @smith_integrated_2011 using `R` package `worldmet` [@carslaw_worldmet_2023]. [Vaccine data](https://www.data.gouv.fr/fr/datasets/donnees-relatives-aux-personnes-vaccinees-contre-la-covid-19-1/) can be downloaded from @etalab_les_2020. EHRs data can be downloaded on dryad [@ferte_benefit_2023]. For privacy issues, publicly available EHRs data below 10 patients were obfuscated to 0. For convenience, all data were downloaded, merged and provided as replication material.

### Evaluation framework

The task was to forecast 14 days ahead the number of hospitalized patients. As seen at @sec-basicregression, we will train the model to predict the variation of hospitalization, denoted as $hosp$, defined as $outcome_{t+14} = hosp_{t+14} - hosp_{t}$ with $t = 1, ..., T$. Metrics computation and visualizations will be performed on the predicted number of hospitalizations denoted as $\widehat{hosp_{t+14}} = \widehat{outcome_{t+14}} + hosp_{t}$.

The dataset was separated into two periods. First period from May 16, 2020 to March 1, 2021 served to identify relevant hyperparameters. Remaining data was used to evaluate the model performance.

The performance of the model was evaluated according to several metrics:

- the mean absolute error : $\text{MAE} = \frac{1}{T} \sum_{t=1}^{T} \left| \hat{hosp}_{t+14} - hosp_{t+14} \right|$.
- the median relative error : $\text{MRE} = \text{median} \left( \left| \frac{\hat{hosp}_{t+14} - hosp_{t+14}}{hosp_{t+14}} \right| \right)$.
- the mean absolute error to baseline : $\text{MAEB} = \frac{1}{T} \sum_{t=1}^{T} \left( \left| \hat{hosp}_{t+14} - hosp_{t+14} \right| - \left| hosp_{t} - hosp_{t+14} \right| \right)$.
- the median relative error to baseline : $\text{MREB} = \text{median} \left( \left| \frac{\hat{hosp}_{t+14} - hosp_{t+14}}{hosp_{t} - hosp_{t+14}} \right| \right)$)

Median was chosen over mean for $MRE$ and $MREB$ because those metrics tend to have extremely high values when the denominator is close to 0 (i.e when the number of hospitalized patients is close to 0 or the number of patients hospitalized at 14 days is close to the current number of hospitalized patients respectively). $MAEB$ and $MREB$ compare model performance to a baseline model which predicts the current number of hospitalized patients at 14 days. Those metrics help to determine the information added by the model and is a good baseline as covid-19 forecast model do not always outperform this basic forecast (@cramer_evaluation_2022-1).

Because the outcome is obfuscated below 10 hospitalizations for privacy reason, we set both the outcome and the forecast to 10 when the observed value was 0 or the forecasted value was below 10 when evaluating the model performance.

### Models

We compared RC to elastic-net penalized regression (denoted as Enet). Furthermore we evaluated RC based on several architectures. First we compared RC with a single input scaling common to all features and a RC with a specific input scaling per feature. Second we compared RC where the input layer is connected to the output layer in addition to the connection between reservoir and output layer. Therefore, five models were evaluated :

- Elastic-net penalized regression denoted *Enet*
- RC with a single input scaling and no connection between input and ouput layers denoted *Common IS R %>>% O*
- RC with a single input scaling and connection between input and ouput layers denoted *Common IS I+R %>>% O*
- RC with multiple input scaling and no connection between input and ouput layers denoted *Multiple IS R %>>% O*
- RC with multiple input scaling and connection between input and ouput layers denoted *Multiple IS I+R %>>% O*

Because of the randomness of the reservoir, we took the median forecast of 10 reservoir on the train set to evaluate the performance of a given hyperparameter set. On the test set we aggregated the forecast of 40 reservoirs, each of them having one of the 40 best hyperparameter sets found on the train set. In addition, because covid-19 hospitalization is a non-stationary process, models were re-trained everyday using all previous days. To ease computation burden, only one day over two was used to find hyperparameters on the training set.

### Hyperparameter optimisation using random search

RC relies mainly on 4 hyperparameters including the leaking rate (i.e "memory" parameter), spectral radius (i.e "chaoticity" parameter), input scaling (i.e "feature gain" parameter) and ridge (i.e penalization parameter). Input scaling can be either, common to all features or specific to each feature which increases the number of hyperparameter by the number of features.

Following the notation from `glmnet` package [@friedman_regularization_2010], elastic-net penalized linear regression relies on two hyperparameters, lambda (i.e the penalization parameter) and alpha (i.e the compromise between lasso and ridge penalty)

Hyperparameter were selected in the training set (i.e before March 1, 2021) using a wrapper approach and a random search sampler using 2000 samples for each model. The sampling distribution were defined as follow :

- (RC) ridge and (Enet) lambda : log-uniform law defined between 1e-10 and 1e5
- (RC) input scaling and spectral radius : log-uniform law defined between 1e-5 and 1e5
- (RC) leaking rate : log-uniform law defined between 1e-3 and 1
- (Enet) alpha : uniform defined between 0 and 1

We provided large search space for all hyper-parameters. Search space was slightly reduced for leaking rate based on previous results and because a leaking rate of 1e-3 already imply that new inputs make the reservoir change really slowly which is not inline with the dynamic of covid-19 but would be appropriate for an application where the phenomena to forecast has a slow dynamic.

Finally, we provided an additional Enet model similar to the one in @ferte_benefit_2022 where alpha was set to $0.5$ and lambda was re-evaluated everyday in the test set based on previous data using the cross-validation procedure provided by `glmnet`.

## Results

```{r echo=FALSE}
# because computing time for this section is long, all results were computed
# using a calculation server and stored into a rds file
ls_use_case <- readRDS(file = here::here("data/precomputed_results.rds"))
```

The goal of this task is to predict 14 days ahead the hospitalization. @fig-ucPresentData shows both the training set (i.e before 2021-03-01) and the test set where the blue curve correspond to the input features (first derivatives are not shown) and the orange curves correspond to the outcome the model is trained on (i.e the hospitalization variation) and the hospitalizations at 14 days on which the performance metrics are computed. The figures outline that the relation between the input features and the outcome evolve over time and that the time series is not stationary. For instance IPTCC (*Index PREDICT de Transmissivité Climatique de la COVID-19*) seems correlated to the outcome except that it completely miss the summer 2021 increase.

```{r ucPresentData, echo = FALSE}
#| label: fig-ucPresentData
#| fig-cap: "Covid-19 epidemic at BUH. Outcome of interest is presented in orange. Model is trained to forecast Outcome curve which corresonds to the difference between Hospitalisatiosn at 14 days and current hospitalisations. Other features are scaled (divide by the maximum of the feature) represented in darkblue."
#| fig-height: 8
# descriptive plot of the data
ls_use_case$plot_present_data
```

### Hyperparameter selection

@fig-ucHyperparam shows the hyperparameter optimisation using random search for the different RC architectures. We observe that model with multiple input scaling achieved better performance on the train set compared to model with single input scaling which is expected as they can adapt more closely to the data thanks to specific input scaling for each feature.

As expected, we observe that the optimal leaking rate is above 1e-2 for all RC which is coherent with the short term dynamic of covid-19 epidemic. Trends for other hyperparameters are less clear even though best hyperparameters sets were close for RC with common input scaling and for RC with multiple input scaling.

```{r ucHyperparam, echo=FALSE}
#| label: fig-ucHyperparam
#| fig-cap: "Hyperparameter evaluation on training set by random search. Hp sets with MAE above 30 were removed for clarity of visualisation."
#| fig-height: 7
# hyperparameter search
ls_use_case$plot_reservoir_hp
```

@fig-ucHyperparamMultipleIS shows the hyperparameter search for RC with multiple input scaling and connected input layer. We observe that the random search tends to favor high importance given to derivative of positive RT-PCR (including the elderly) and the derivative of IPTCC. The remaining features do not exhibit a clear pattern.

```{r ucHyperparamMultipleIS, echo=FALSE}
#| label: fig-ucHyperparamMultipleIS
#| fig-cap: "Hyperparameter evaluation on training set by random search of the model with multiple input scaling and no connection between input layer and output layer. Hp sets with MAE above 30 were removed for clarity of visualisation."
#| fig-height: 9
# hyperparameter search, focus on input scaling
ls_use_case$plot_feature_input_scaling
```

### Forecast performance

```{r performance, echo = FALSE}
#| label: tbl-performance
#| tbl-cap: "Model performance with several reservoir configuration. For each setting, 40 reservoirs are computed and the forecast is the median of the 40 forecasts. Results show the performance metrics : MAE = Mean Absolute Error, MRE = Median Relative Error, MAEB = Mean Absolute Error to Baseline, MREB = Median Relative Error to Baseline."
# performance of the different model
ls_use_case$table_perf_esn %>%
  dplyr::mutate(model = gsub(model,
                             pattern = "IS \n\n", replacement = "IS:")) %>%
  dplyr::rename(
    Model = model,
    MAE = mae,
    MRE = mre,
    MAEB = mae_baseline,
    MREB = mre_baseline
  ) %>%
  knitr::kable(
    digits = 2,
    caption = "Model Performance",
    format = "html" # Use "latex" for LaTeX output or "markdown" for plain Markdown
  )
```

@tbl-performance shows the performance on the test set. Best model according to all metrics was RC with common input scaling and connection between input and output layers. Having one input scaling per feature did not improve the model which might be due to low generalisability of the hyperparameter of the training set to the test set due to non-stationarity. Additionaly, connecting input layer to output layer improved the model forecast. All RC models performed better than the elastic-net model.

@fig-forecastwithorwithoutUpdate shows the forecast of the different models. We note that models struggle to accurately forecast slope shifts. For instance, summer 2021 initial increase is partially predicted by all models but its decrease is not well predicted. Winter 2021 increase is anticipated by all models but they tend to overestimate it because of the rise of vaccine effect.

```{r forecastwithorwithoutUpdate, echo = FALSE}
#| label: fig-forecastwithorwithoutUpdate
#| fig-cap: "Reservoir computing forecast depending on the setting with and without monthly update. Red line is the median forecast of 40 reservoirs. Grey lines are individual forecast of each of the 40 reservoirs."
#| fig-height: 6
# plot of the forecast of the different models
ls_use_case$plot_forecast
```

### Number of model to aggregate

@fig-ucAggregationSpread show the individual forecast for the 40 best sets of hyperparameters of each RC architecture. Due to the internal random connection of the reservoir, we observe forecast stochasticity and relying on only one forecast is unreliable. We explored the number of model needed at @fig-ucAggregationNb which shows that after 10 models, forecast is stable and even 5 models for the simpler model with common input scaling which rely on less hyperparamters.

```{r ucAggregationSpread, echo = FALSE}
#| label: fig-ucAggregationSpread
#| fig-cap: "Individual forecast the 40 best hyperparameter sets for the different RC configuration. Forecast value above 200 were set to 200 for clarity."
# plot of different models without forecast aggregation.
ls_use_case$plot_before_aggregation_forecast
```

```{r ucAggregationNb, echo = FALSE}
#| label: fig-ucAggregationNb
#| fig-cap: "Mean absolute error depending on the number of aggregated reservoir."
# plot models depending on number of aggregated reservoir.
ls_use_case$plot_aggregation
```

### Input feature importance

We compared the coefficients of the output layer estimated for the input layer and the reservoir nodes. Additionally, we compared the coefficient given to the input layer by the output layer in the reservoir and the coefficient estimated by the elastic-net model.

@fig-importanceReservoir illustrates the ranking of input layer compared to all connections to the output layer, including the 500 reservoir nodes and the 16 features of the input layer (excluding bias). The figure shows that the model with common input scaling tends to assign less weight to input layer compared to the model with multiple input scaling. This suggests that the reservoir with common input scaling provides more information than the reservoir with multiple input scaling, which aligns with its better performance, as shown in Table @tbl-performance.

```{r importanceReservoir, echo = FALSE}
#| label: fig-importanceReservoir
#| fig-cap: "Mean feature importance of the 40 best hyperparameter sets by model, focus on the connection between the input and output layers. Models with direct connection between input and output layer are included. The rank is obtained by comparing the feature input layer and all other connection coefficients (both input and reservoir corresponding coefficients) attributed by the output layer at each date for each hyperparameter set. The higher the output layer's coefficient for the input layer, the closer its rank will be to 1 and the more important the feature is."
#| fig-height: 8
# Plot raw feature importance
ls_use_case$plot_reservoir_importance
```

Furthermore, @fig-importanceReservoirvsEnet compares the coefficients assigned to input features by the elastic-net model and the RC models. While the coefficients are generally consistent across RC models, there are some notable differences with elastic-net. Specifically, certain features deemed important by the elastic-net model, such as the derivative of RT-PCR, and the derivative of Vaccine, are less important for the reservoir computing model. This may indicate that these features predictive ability is better conveyed by their relationship with other features, which is captured by the reservoir computing model but might not be by the elastic-net model. Conversely, emergency, IPTCC, proportion of positive RT-PCR, and hospitalizations are more important for the reservoir computing model than for the elastic-net model.

```{r importanceReservoirvsEnet, echo = FALSE}
#| label: fig-importanceReservoirvsEnet
#| fig-cap: "Mean feature coefficient of the 40 best hyperparameter sets by model and the elastic-net model. Only models with direct connection between input and output layer are included. The coefficients were calculated as the average value across all dates for each feature, model and hyperparamet set."
#| fig-height: 8
# Plot feature importance of different models
ls_use_case$plot_importance
```


## Discussion


In this specific application, we have demonstrated that RC exhibits commendable performance in comparison to Elastic-net, which serves as the reference model. Furthermore, we highlight the inherent challenges in forecasting within this context, primarily stemming from the non-stationarity of the time series.

All computations in this study were conducted using the `reservoirnet` package, and the entire codebase is accessible on Zenodo [@ferte_thomasfertejss_reservoirnet_2024]. This `R` package demonstrates its efficacy in implementing various reservoir architectures, including connection between the input layer and the output layer, as well as the utilization of several input scaling, all within the context of a real-world use case.

Given the substantial number of hyperparameters involved, we acknowledge that random search may not be the most efficient optimization algorithm. We have retained this approach for the sake of simplicity in this tutorial paper; however, meta-heuristic approaches, particularly those utilizing evolutionary algorithms, may prove more efficient, especially when employing multiple input scaling [@bala_applications_2018; @ferte_optimizing_2024]. 

This study represents a novel contribution to epidemic forecasting utilizing RC. Notably, previous literature predominantly focused on simpler problems characterized by fewer input features or shorter evaluation periods [@liu_nanophotonic_2023; @ray_optimized_2021; @ghosh_reservoir_2021]. Our findings underscore the potential of this approach for future epidemics, suggesting its potential to surpass more traditional epidemiological tools while maintaining a lightweight model structure compared to other RNNs.

It is worth noting that all models, including those presented in @ferte_benefit_2022, face challenges in accurately predicting slope shifts, highlighting the need for further investigation. Specifically, additional work is required to extend the application of Reservoir Computing (RC) to high-dimensional settings, building upon insights gained from models that use a more extensive feature set. While RC has demonstrated promising performance for epidemic forecasting in high-dimensional settings, this task remains challenging [@ferte_reservoir_2024].

A new perspective may emerge from integrating New Generation Computing, a method inspired by RC and nonlinear vector-autoregression, where expert insights into the non-linear components of the model can be directly embedded within the reservoir [@zhang2022catch22s]. Additionally, we observe that reservoir predictions exhibit high instability, requiring the aggregation of multiple predictions to achieve meaningful results. To address this instability, @zhang2024instability suggests implementing stronger penalization techniques that can be updated as more data becomes available or adopting a "training with noise" approach, where noise is added during training for regularization. These approaches could help mitigate instability in reservoir computing as the problem's dimensionality increases.

# Discussion and conclusion {#sec-discussion-and-conclusion}

In this paper, we introduce the `R` package `reservoirnet`, which serves as a versatile tool for implementing reservoir computing based on `ReservoirPy`'s `Python` library. It offers flexibility in defining the reservoir architecture, including options for specifying connections between the input layer and the output layer, as well as variations in input scaling as demonstrated on a real-world use case.

We provided a comprehensive overview of the basic usage of the `reservoirnet` package through illustrative examples in regression and classification tasks. This introductory section serves as a foundation for `R` users, offering step-by-step guidance on constructing and training reservoir computing models using the package. By demonstrating the application of RC in both regression and classification scenarios, we aim to equip users with the essential knowledge and skills needed to harness the capabilities of reservoir computing for diverse tasks.

Drawing on the robust foundation of the `ReservoirPy` structure, a well-maintained `Python` library, this package inherits its reliability and longevity. We have focused on providing access to the fundamental features, building upon the strong base provided by `ReservoirPy`. Therefore, this initial version of `reservoirnet` must evolve in tandem with the growing understanding and adoption of RC within the `R` community.

<!-- # Introduction -->

<!-- ## About this document -->

<!-- This document, accompanied with the [hopefully finely tuned git repos](https://github.com/computorg/template-computo-R/), provides a template for writing contributions to **Computo** [@computo]. We show how `R` code [@R-base] can be included and how the repository can be set up for triggering github actions for rendering the document, with dependencies handled by `renv`. -->

<!-- ## Setup a github repository for preparing your submission -->

<!-- You can start by clicking the **"use this template"** button, on the top of the page of the [github repository associated to this document](https://github.com/computorg/template-computo-R/). Of course, you can set your repository private during the preparation of your manuscript. -->

<!-- ## Quarto -->

<!-- [Quarto](https://quarto.org/) is a versatile formatting system for authoring documents integrating markdown, LaTeX and code blocks interpreted either via Jupyter or Knitr (thus supporting Python, R and Julia). It relies on the [Pandoc](https://pandoc.org/MANUAL.html) document converter. -->

<!-- ## Requirements -->

<!-- You need [quarto](https://quarto.org/) installed on your system and the [Computo extension](https://github.com/computorg/computo-quarto-extension) to prepare your document. For the latter, once quarto is installed,  run the following to install the extension in the current directory (it creates a `_extension` directory which is ignored by git thanks to `.gitignore` by default): -->

<!-- ```.bash -->
<!-- quarto add computorg/computo-quarto-extension -->
<!-- ``` -->

<!-- [`R`](https://www.r-project.org/) and the following `R` packages must be installed on your computer: [`knitr`](https://cran.r-project.org/package=knitr), [`markdown`](https://cran.r-project.org/package=markdown). -->

<!-- ## Link with your usual tools -->

<!-- Quarto is expecting a `.qmd` markdown file, but will also works with a standard [`Rmarkdown`](https://rmarkdown.rstudio.com/) (`.Rmd`) file. In addition, especially if you are not comfortable with the command line interface, quarto is fully integrated inside the [Rstudio IDE](https://quarto.org/docs/get-started/hello/rstudio.html) so that you can write and build your quarto document inside Rstudio. -->

<!-- Quarto can also process a [Jupyter notebook](https://quarto.org/docs/get-started/hello/jupyter.html) file if you are used to it (it will just require to add the proper YAML metadata^[the same metadata as in the [`template-computo-R.qmd` file](https://github.com/computorg/template-computo-R/blob/main/template-computo-R.qmd) in the first cell, type "Raw", of the notebook]). -->

<!-- **Note**: _More advanced Jupyter-related functionality like Myst/Jupyter book are not supported in this Quarto setup. The markdown syntax inside the Jupyter notebook should follow the Quarto syntax (c.f. [below](#formatting)). If you are more comfortable with using Myst/Jupyter book, we provide a [specific template](https://github.com/computorg/template-computo-myst) but it will requires more formatting work for Computo editorial team, thus highly encourage authors to use the Quarto templates._ -->

<!-- # Formatting -->

<!-- This section covers basic formatting guidelines for quarto documents. -->

<!-- To render a document, run `quarto render`. By default, both PDF and HTML documents are generated: -->

<!-- ```.bash -->
<!-- quarto render template-computo-R.qmd # will render both to html and PDF -->
<!-- ``` -->

<!-- ::: {.callout-tip} -->
<!-- ## Note -->

<!-- To check the syntax of the formatting below, you can use the `</> source` button at the top left of this document. -->
<!-- ::: -->

<!-- ## Basic markdown formatting -->

<!-- **Bold text** or _italic_ -->

<!-- - This is a list -->
<!-- - With more elements -->
<!-- - It isn't numbered. -->

<!-- But we can also do a numbered list -->

<!-- 1. This is my first item -->
<!-- 2. This is my second item -->
<!-- 3. This is my third item -->

<!-- ## Mathematics -->

<!-- ### Mathematical formulae -->

<!-- [LaTeX](https://www.latex-project.org/) code is natively supported[^lualatex], which makes it possible to use mathematical formulae: -->

<!-- [^lualatex]: We use [lualatex](https://lualatex.org/) for this purpose. -->

<!-- $$ -->
<!-- f(x_1, \dots, x_n; \mu, \sigma^2) = -->
<!-- \frac{1}{\sigma \sqrt{2\pi}} \exp{\left(- \frac{1}{2\sigma^2}\sum_{i=1}^n(x_i - \mu)^2\right)} -->
<!-- $$ -->

<!-- It is also posible to cross-reference an equation, see @eq-mylabel: -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- D_{x_N} & = \frac12 -->
<!-- \left[\begin{array}{cc} -->
<!-- x_L^\top & x_N^\top \end{array}\right] \, -->
<!-- \left[\begin{array}{cc}  L_L & B \\ B^\top & L_N \end{array}\right] \, -->
<!-- \left[\begin{array}{c} -->
<!-- x_L \\ x_N \end{array}\right] \\ -->
<!-- & = \frac12 (x_L^\top L_L x_L + 2 x_N^\top B^\top x_L + x_N^\top L_N x_N), -->
<!-- \end{aligned} -->
<!-- $$ {#eq-mylabel} -->

<!-- ### Theorems and other amsthem-like environments -->

<!-- Quarto includes a nice support for theorems, with predefined prefix labels for theorems, lemmas, proposition, etc. see [this page](https://quarto.org/docs/authoring/cross-references.html#theorems-and-proofs). Here is a simple example: -->

<!-- ::: {#thm-slln} -->
<!-- ## Strong law of large numbers -->

<!-- The sample average converges almost surely to the expected value: -->

<!-- $$\overline{X}_n\ \xrightarrow{\text{a.s.}}\ \mu \qquad\textrm{when}\ n \to \infty.$$ -->
<!-- ::: -->

<!-- See @thm-slln. -->

<!-- ## R Code -->

<!-- Quarto uses either Jupyter or knitr to render code chunks. This can be triggered in the yaml header. In this tutorial, we use `knitr` (`R` and packages `knitr`, `markdown` must be installed on your computer). -->

<!-- ``` yaml -->
<!-- --- -->
<!-- title: "My Document" -->
<!-- author "Jane Doe" -->
<!-- --- -->
<!-- ``` -->

<!-- `R` code [@R-base] chunks may be embedded as follows: -->

<!-- ```{r r-code, echo=TRUE} -->
<!-- x <- rnorm(10) -->
<!-- ``` -->

<!-- ## Figures -->

<!-- Plots can be generated as follows: -->

<!-- ```{r pressure, message = FALSE} -->
<!-- library("ggplot2") -->
<!-- p <- ggplot(mpg, aes(displ, hwy)) + -->
<!--   geom_point() + -->
<!--   geom_smooth() -->
<!-- p -->
<!-- ``` -->

<!-- It is also possible to create figures from static images: -->

<!-- :::{#fig-logo} -->

<!-- ![](https://computo.sfds.asso.fr/assets/img/logo_text_vertical.png){height=200} -->

<!-- Computo logo (label) -->
<!-- ::: -->

<!-- **Note:** _Until Quarto version 1.3+ is released, including a remote image (from a web URL) in a document (like the image above) will work in the rendered HTML document but will generate an error when building the PDF document (c.f. [related bug report](https://github.com/quarto-dev/quarto-cli/issues/4443))._ -->

<!-- ## Tables -->

<!-- Tables (with label: `@tbl-mylabel` renders @tbl-mylabel) can be generated with markdown as follows -->

<!-- | Tables   |      Are      |  Cool | -->
<!-- |----------|:-------------:|------:| -->
<!-- | col 1 is |  left-aligned | $1600 | -->
<!-- | col 2 is |    centered   |   $12 | -->
<!-- | col 3 is | right-aligned |    $1 | -->
<!-- : my table caption {#tbl-mylabel} -->

<!-- Table can also be generated by some code, for instance with knitr here: -->

<!-- ```{r cars} -->
<!-- knitr::kable(summary(cars), caption = "Table caption.") -->
<!-- ``` -->

<!-- ## Handling references {#sec-references} -->

<!-- ### Bibliographic references -->

<!-- References are displayed as footnotes using -->
<!-- [BibTeX](http://www.bibtex.org/), e.g. `[@computo]` will be displayed -->
<!-- as [@computo], where `computo` is the bibtex key for this specific -->
<!-- entry. The bibliographic information is automatically retrieved from -->
<!-- the `.bib` file specified in the header of this document (here: -->
<!-- `references.bib`). -->

<!-- ### Other cross-references -->

<!-- As already (partially) seen, Quarto includes a mechanism similar to the -->
<!-- bibliographic references for sections, equations, theorems, figures, -->
<!-- lists, etc. Have a look at [this -->
<!-- page](https://quarto.org/docs/authoring/cross-references.html). -->

<!-- ## Advanced formatting -->

<!-- Advanced formatting features are possible and documented (including interactive plots, pseudo-code, (Tikz) diagrams, Lua filters, mixing R + Python in the same document), but are beyond the scope of this simple introduction. We point several entries in this direction. -->

<!-- ::: {.callout-warning} -->
<!-- ## More information -->

<!-- - [The Quarto web site](https://quarto.org) for comprehensive documentation, including: -->
<!--   + [Tutorial](https://quarto.org/docs/get-started/) -->
<!--   + [User guide](https://quarto.org/docs/guide/) -->
<!--   + [Options reference](https://quarto.org/docs/reference/) -->

<!-- - [The template distributed with the Computo Quarto extension](https://computo.sfds.asso.fr/computo-quarto-extension/), which uses such advanced features. -->

<!-- - [Our mock version of the t-SNE paper](https://computo.sfds.asso.fr/published-paper-tsne/), a full and advanced example using Python and the Jupyter kernel. -->

<!-- - [The previously published papers in Computo](https://computo.sfds.asso.fr/publications/) can be used as references. -->

<!-- ::: -->

<!-- # Finalize your submission -->

<!-- ## Handle `R` dependencies with `renv` -->

<!-- To make your work reproducible, you need to fix the packages and environment used to run your analysis. For the `R` system, the `renv` package is one of the possible reliable method, supported by the community. You basically need a couple of commands to setup your environment on your local machine. First, -->

<!-- ```{r, eval = FALSE} -->
<!-- renv::init() -->
<!-- ``` -->

<!-- will initialize your repository. Then you just need to install the dependencies required to run your contribution, for instance,  -->


<!-- ```{r, eval=FALSE} -->
<!-- renv::install("ggplot2") # or equivalently install.packages("ggplot2") -->
<!-- ``` -->

<!-- Non-CRAN packages (*e.g.* Github packages) can be used. Once you are done, you can fix everything with the command -->

<!-- ```{r, eval=FALSE} -->
<!-- renv::snapshot() -->
<!-- ``` -->

<!-- ::: {.callout-important} -->
<!-- The only file that needs to be versioned by git is `renv.lock`. By default, the rest is ignored thanks to `.gitignore`.  -->
<!-- ::: -->

<!-- More details for using `renv` can be found either -->

<!-- - on the [`renv` packge webpage](https://rstudio.github.io/renv/articles/renv.html), or -->
<!-- - on the [quarto page dedicated to environments](https://quarto.org/docs/projects/virtual-environments.html#using-renv) -->

<!-- ## Continuous integration -->

<!-- The repository associated with this template is pre-configure to trigger an action on push that performs the following: -->

<!-- 1. Check out repository on the `ubuntu-latest` machine -->
<!-- 2. Install quarto and dependencies, including the Computo extension -->
<!-- 3. Install R and dependencies with `renv`, using your `renv.lock` file -->
<!-- 4. Render your .qmd file and Publish the results on a gh-page (both HTML and PDF) -->

<!-- The file [.github/workflows/build.yml](https://github.com/computorg/template-computo-R/blob/main/.github/workflows/build.yml) is largely inspired from [this file](https://quarto.org/docs/publishing/github-pages.html#example-knitr-with-renv). -->

<!-- Once this is successful, you are ready to submit your manuscript to the [Computo submission platform](https://computo.scholasticahq.com/). -->

<!-- ::: {.callout-warning} -->
<!-- The first time, you possibly need to create the branch for the action to work. This can be done by running the following command from your computer, in your git repository: -->

<!-- ```.bash -->
<!-- quarto publish gh-pages -->
<!-- ``` -->

<!-- Then, set the branch `gh-page` as the source of your github page, and trigger the action to check that everything works fine. -->
<!-- ::: -->

<!-- ## Data and large files -->

<!-- If your submission materials contain files larger than 50MB, **especially data files**, they won’t fit on a git repository as is. For this reason, we encourage you to put your data or any materials you deem necessary on an external “open data” centered repository hub such a [Zenodo](https://zenodo.org/) or [OSF](https://osf.io/). -->

# Acknowledgements {.unnumbered}

We thank Romain Griffier for his expertise on the Bordeaux University Hospital Data.

Experiments presented in this paper were conducted using the PlaFRIM experimental testbed, supported by Inria, CNRS (LABRI and IMB), Université de Bordeaux, Bordeaux INP and Conseil Régional d’Aquitaine (see https://www.plafrim.fr), as well as by the MCIA (Mésocentre de Calcul Intensif Aquitain).

This study was carried out in the framework of the University of Bordeaux's France 2030 program / RRI PHDS.

# References {.unnumbered}

::: {#refs}
:::

# Session information {.appendix .unnumbered}

```{r session-info}
sessionInfo()
```

